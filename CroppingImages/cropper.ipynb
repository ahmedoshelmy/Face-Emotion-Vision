{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from commonfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in '../Data/Student-engagement-dataset/'.\n",
      "There are 3 directories and 0 images in '../Data/Student-engagement-dataset/Engaged'.\n",
      "There are 0 directories and 369 images in '../Data/Student-engagement-dataset/Engaged\\confused'.\n",
      "There are 0 directories and 347 images in '../Data/Student-engagement-dataset/Engaged\\engaged'.\n",
      "There are 0 directories and 360 images in '../Data/Student-engagement-dataset/Engaged\\frustrated'.\n",
      "There are 4 directories and 0 images in '../Data/Student-engagement-dataset/Not engaged'.\n",
      "There are 0 directories and 358 images in '../Data/Student-engagement-dataset/Not engaged\\bored'.\n",
      "There are 2 directories and 0 images in '../Data/Student-engagement-dataset/Not engaged\\cropped'.\n",
      "There are 0 directories and 4 images in '../Data/Student-engagement-dataset/Not engaged\\cropped\\drowsy'.\n",
      "There are 0 directories and 90 images in '../Data/Student-engagement-dataset/Not engaged\\cropped\\Looking Away'.\n",
      "There are 0 directories and 263 images in '../Data/Student-engagement-dataset/Not engaged\\drowsy'.\n",
      "There are 0 directories and 423 images in '../Data/Student-engagement-dataset/Not engaged\\Looking Away'.\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = \"../Data/Student-engagement-dataset/\"\n",
    "images_paths = [ROOT_PATH+img for img in os.listdir(ROOT_PATH)]\n",
    "\n",
    "\n",
    "\n",
    "walk_through_dir(ROOT_PATH)\n",
    "\n",
    "# for path in images_paths:\n",
    "#     img, sucess = process_image(path)\n",
    "#     if sucess:\n",
    "#         plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye_glasses_haarCascade = cv2.CascadeClassifier(\n",
    "#     '../Haar/opencv/haarcascade_eye_tree_eyeglasses.xml')\n",
    "# face_haarCascade = cv2.CascadeClassifier(\n",
    "#     \"../Haar/opencv/haarcascade_frontalface_default.xml\")\n",
    "# eye_haarCascade = cv2.CascadeClassifier(\n",
    "#     \"../Haar/opencv/haarcascade_eye.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cropped_image_if_2_eyes(image_path):\n",
    "#     # p = image_path = r\".\\images\\news.jpg\"\n",
    "\n",
    "#     img = cv2.imread(image_path)\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     faces = face_haarCascade.detectMultiScale(img, 1.3, 5)\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         roi_gray = gray[y:y+h, x:x+w]\n",
    "#         roi_color = img[y:y+h, x:x+w]\n",
    "#         eyes = eye_haarCascade.detectMultiScale(roi_gray)\n",
    "#         if len(eyes) < 2:\n",
    "#             eyes = eye_glasses_haarCascade.detectMultiScale(roi_gray, 1.1)\n",
    "#         if len(eyes) >= 2:\n",
    "#             return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"..\\Data\\Student-engagement-dataset\\Engaged\"\n",
    "path_to_cr_data = \"..\\Data\\Student-engagement-dataset\\Engaged\\cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def get_image_paths(root_folder, image_extensions=['jpg', 'jpeg', 'png', 'gif']):\n",
    "    image_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                image_paths.append(root+\"/\"+file)\n",
    "\n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)\n",
    "\n",
    "if os.path.exists(path_to_cr_data):\n",
    "    shutil.rmtree(path_to_cr_data)\n",
    "os.mkdir(path_to_cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cropped images in folder:  ..\\Data\\Student-engagement-dataset\\Engaged\\cropped\\confused\n",
      "Generating cropped images in folder:  ..\\Data\\Student-engagement-dataset\\Engaged\\cropped\\engaged\n",
      "Generating cropped images in folder:  ..\\Data\\Student-engagement-dataset\\Engaged\\cropped\\frustrated\n"
     ]
    }
   ],
   "source": [
    "cropped_image_dirs = []\n",
    "person_file_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    count = 0\n",
    "    person_name = img_dir.split('\\\\')[-1]\n",
    "    person_file_names_dict[person_name] = []\n",
    "    \n",
    "    for entry in get_image_paths(img_dir):\n",
    "        # image,res = process_image(entry.path)\n",
    "        # if(res==False):\n",
    "        #     continue\n",
    "\n",
    "        faces, colorfaces, faces_with_edges, responses = get_faces_with_eyes(cv2.imread(entry))\n",
    "        \n",
    "        # roi_color = get_cropped_image_if_2_eyes(entry)\n",
    "        for i in range(len(colorfaces)):\n",
    "            if colorfaces[i] is not None:\n",
    "                cropped_folder = path_to_cr_data+'\\\\'+person_name\n",
    "                if not os.path.exists(cropped_folder):\n",
    "                    os.mkdir(cropped_folder)\n",
    "                    cropped_image_dirs.append(cropped_folder)\n",
    "                    print(\"Generating cropped images in folder: \", cropped_folder)\n",
    "                cropped_file_name = person_name+str(count)+\".png\"\n",
    "                cropped_file_path = cropped_folder+'\\\\'+cropped_file_name\n",
    "                cv2.imwrite(cropped_file_path, colorfaces[i])\n",
    "                person_file_names_dict[person_name].append(cropped_file_path)\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"..\\\\Data\\\\Student-engagement-dataset\\\\Not engaged\"\n",
    "path_to_cr_data = \"..\\\\Data\\\\Student-engagement-dataset\\\\Not engaged\\\\cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)\n",
    "\n",
    "if os.path.exists(path_to_cr_data):\n",
    "    shutil.rmtree(path_to_cr_data)\n",
    "os.mkdir(path_to_cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cropped images in folder:  ..\\Data\\Student-engagement-dataset\\Not engaged\\cropped\\bored\n",
      "Generating cropped images in folder:  ..\\Data\\Student-engagement-dataset\\Not engaged\\cropped\\drowsy\n",
      "Generating cropped images in folder:  ..\\Data\\Student-engagement-dataset\\Not engaged\\cropped\\Looking Away\n"
     ]
    }
   ],
   "source": [
    "cropped_image_dirs = []\n",
    "person_file_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    count = 0\n",
    "    person_name = img_dir.split('\\\\')[-1]\n",
    "    person_file_names_dict[person_name] = []\n",
    "    for entry in get_image_paths(img_dir):\n",
    "        faces,colorfaces, faces_with_edges, responses = get_faces_with_eyes(cv2.imread(entry))\n",
    "        \n",
    "        # roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        for i in range(len(colorfaces)):\n",
    "            if colorfaces[i] is not None and responses[i] == \"Success\":\n",
    "                cropped_folder = path_to_cr_data+'\\\\'+person_name\n",
    "                if not os.path.exists(cropped_folder):\n",
    "                    os.mkdir(cropped_folder)\n",
    "                    cropped_image_dirs.append(cropped_folder)\n",
    "                    print(\"Generating cropped images in folder: \", cropped_folder)\n",
    "                cropped_file_name = person_name+str(count)+\".png\"\n",
    "                cropped_file_path = cropped_folder+'\\\\'+cropped_file_name\n",
    "                cv2.imwrite(cropped_file_path, colorfaces[i])\n",
    "                person_file_names_dict[person_name].append(cropped_file_path)\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
